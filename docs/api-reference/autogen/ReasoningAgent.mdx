---
sidebarTitle: ReasoningAgent
title: autogen.ReasoningAgent
---
<h2 id="autogen.ReasoningAgent" class="doc doc-heading">
    <code class="doc-symbol doc-symbol-heading doc-symbol-class"></code>
    <span class="doc doc-object-name doc-class-name">ReasoningAgent</span>
</h2>

```python
ReasoningAgent(
    name: str,
    llm_config: dict[str, typing.Any],
    grader_llm_config: dict[str, typing.Any] | None = None,
    max_depth: int = 4,
    beam_size: int = 3,
    answer_approach: str = 'pool',
    verbose: bool = True,
    reason_config: dict[str, typing.Any] | None = None,
    **kwargs: Any
)
```

    (In preview) Assistant agent, designed to solve a task with LLM.<br/>AssistantAgent is a subclass of ConversableAgent configured with a default system message.<br/>The default system message is designed to solve a task with LLM,
    including suggesting python code blocks and debugging.<br/>`human_input_mode` is default to "NEVER"
    and `code_execution_config` is default to False.<br/>This agent doesn't execute code by default, and expects the user to execute the code.<br/>Initialize a ReasoningAgent that uses tree-of-thought reasoning.<br/>

<b>Parameters:</b>
| Name | Description |
|--|--|
| `name` | **Type:** `str` |
| `llm_config` | **Type:** `dict[str, typing.Any]` |
| `grader_llm_config` | **Type:** `dict[str, typing.Any] \| None`<br/><br/>**Default:** None |
| `max_depth` | **Type:** `int`<br/><br/>**Default:** 4 |
| `beam_size` | **Type:** `int`<br/><br/>**Default:** 3 |
| `answer_approach` | **Type:** `str`<br/><br/>**Default:** 'pool' |
| `verbose` | **Type:** `bool`<br/><br/>**Default:** True |
| `reason_config` | **Type:** `dict[str, typing.Any] \| None`<br/><br/>**Default:** None |
| `**kwargs` | **Type:** `Any` |

### Instance Attributes

<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>
#### method
<br />

    <br />

### Instance Methods

<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>
#### generate_forest_response

```python
generate_forest_response(
    self,
    messages: list[dict[str, typing.Any]],
    sender: autogen.agentchat.agent.Agent,
    config: dict[str, typing.Any] | None = None
) -> tuple[bool, str]
```

    Generate a response using tree-of-thought reasoning.<br/>

<b>Parameters:</b>
| Name | Description |
|--|--|
| `messages` | Input messages to respond to<br/><br/>**Type:** `list[dict[str, typing.Any]]` |
| `sender` | Agent sending the messages<br/><br/>**Type:** `autogen.agentchat.agent.Agent` |
| `config` | Optional configuration<br/><br/>**Type:** `dict[str, typing.Any] \| None`<br/><br/>**Default:** None |

<b>Returns:</b>
| Type | Description |
|--|--|
| `tuple[bool, str]` | Tuple[bool, str]: Success flag and generated response |

<br />

<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>
#### rate_node

```python
rate_node(
    self,
    node: autogen.agentchat.contrib.reasoning_agent.ThinkNode,
    ground_truth: str = None,
    is_outcome: bool = False
) -> float
```

    Rate the quality of a reasoning path using the grader agent.<br/>

<b>Parameters:</b>
| Name | Description |
|--|--|
| `node` | Node containing the reasoning trajectory to evaluate<br/><br/>**Type:** `autogen.agentchat.contrib.reasoning_agent.ThinkNode` |
| `ground_truth` | Optional ground truth to provide to the grader<br/><br/>**Type:** `str`<br/><br/>**Default:** None |
| `is_outcome` | indicates whether the rating is for an outcome (final answer) or a process (thinking trajectory).<br/><br/>**Type:** `bool`<br/><br/>**Default:** False |

<b>Returns:</b>
| Type | Description |
|--|--|
| `float` | float: Normalized score between 0 and 1 indicating trajectory quality |

<br />